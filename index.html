---
layout: default
title: Venkata Rami Reddy Kallu
---

<h1>Venkata Rami Reddy Kallu</h1>
<p><strong>Researcher | Generative AI Safety | Privacy-Preserving Systems</strong></p>

<p>
  I build <strong>safe, privacy-preserving, and auditable generative AI systems</strong>,
  with a focus on <strong>runtime enforcement, governance, and adversarial robustness</strong>
  across text and audio modalities.
</p>

<hr/>

<h2>About</h2>
<p>
  I work at the intersection of <strong>Generative AI, system safety, and privacy</strong>,
  focusing on how modern AI systems behave <strong>when deployed in real-world, high-trust environments</strong>.
</p>

<p>My work emphasizes <strong>enforceable guarantees over best-effort prompting</strong>, including:</p>
<ul>
  <li>Policy-gated tool execution for LLM agents</li>
  <li>Deterministic validation of tool inputs and outputs</li>
  <li>Grounded, evidence-backed AI summarization</li>
  <li>Privacy-preserving detection of synthetic media</li>
</ul>

<p>
  I am particularly interested in <strong>AI systems that must be auditable, reproducible, and resistant to misuse</strong>,
  even when models behave unexpectedly or adversarially.
</p>

<hr/>

<h2>Projects</h2>
<h3>PolicyGraph</h3>
<p>
  <strong>PolicyGraph</strong> is a policy-gated runtime for
  <strong>safe and auditable Model Context Protocol (MCP) tool execution</strong>.
</p>

<p>It enforces:</p>
<ul>
  <li>Default-deny tool authorization</li>
  <li>Schema-constrained planning (strict JSON only)</li>
  <li>Typed validation of tool outputs</li>
  <li>Evidence-locked summarization to prevent hallucinations</li>
</ul>

<p>
  PolicyGraph is designed as a <strong>governance layer</strong>, not an orchestration framework,
  and provides <strong>model-independent safety guarantees</strong> verified through deterministic evaluation.
</p>

<p><strong>Repository:</strong> <a href="https://github.com/ramsred/policygraph-mcp">https://github.com/ramsred/policygraph-mcp</a></p>

<hr/>

<h2>Patent Highlight</h2>
<h3>Privacy-Preserving Synthetic Voice Detection (Filed Patent)</h3>
<p>
  I am a <strong>co-inventor on a filed patent</strong> focused on
  <strong>privacy-preserving synthetic voice detection</strong>, addressing a critical risk in generative audio systems:
  <strong>speaker identity leakage</strong>.
</p>

<p>The work introduces techniques that:</p>
<ul>
  <li>Detect AI-generated or spoofed speech</li>
  <li>Preserve speaker anonymity and sensitive identity attributes</li>
  <li>Enable deployment in privacy-sensitive and regulated settings</li>
</ul>

<p>
  This research complements my broader focus on <strong>AI safety and governance</strong>, extending similar principles—privacy,
  robustness, and enforceability—from <strong>LLM systems to synthetic media detection</strong>.
</p>

<hr/>

<h2>Research Interests</h2>
<p>
  Generative AI Safety · AI Governance · Privacy-Preserving ML · Synthetic Media Detection · LLM Tooling Systems
</p>
